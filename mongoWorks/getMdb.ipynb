{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta\n",
    "import concurrent.futures\n",
    "import sys\n",
    "import os.path\n",
    "import bson as b\n",
    "\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.sql import types as T \n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import datetime, timedelta \n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext  \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    " \n",
    "\n",
    "def getSpark():\n",
    "    conf = pyspark.SparkConf() \\\n",
    "                .set(\"spark.jars.packages\",\"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "                .set('spark.sql.caseSensitive', True) \\\n",
    "                .setMaster(\"local\") \\\n",
    "                .setAppName(\"sparkaApp\") \\\n",
    "                .setAll([(\"spark.driver.memory\", \"4g\"), (\"spark.executor.memory\", \"6g\")])\n",
    "                \n",
    "    sc = SparkContext(conf=conf)\n",
    "    spark = SparkSession(sc)\n",
    "    return spark\n",
    "\n",
    "local = \"True\"\n",
    "if local == \"True\":\n",
    "    spark = getSpark()\n",
    "    \n",
    "uri_string = \"mongodb://localhost:27017/?readPreference=primary&appname=MongoDB%20Compass&directConnection=true&ssl=false\"\n",
    "dbName = 'local'\n",
    "colName = 'STP'\n",
    "client = MongoClient(uri_string)\n",
    "database = client.get_database(dbName)\n",
    "col = database.get_collection(colName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #.option('spark.mongodb.input.sampleSize', sampleSize) \\\n",
    " #.option('spark.mongodb.input.partitioner', \"MongoSamplePartitioner\") \\\n",
    " #.option('spark.mongodb.input.partitionerOptions.partitionSizeMB', partitionSizeMB) \\\n",
    " #.option('spark.mongodb.input.partitionerOptions.samplesPerPartition', samplesPerPartition) \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PYMONGO METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def colCount():\n",
    "    colCount =  col.find({},{\"_id\"}).count()\n",
    "    return colCount\n",
    "\n",
    "def colFind(limit=\"\"):\n",
    "    if limit == \"\":\n",
    "        colList = [ x for x in col.find()]\n",
    "    else:\n",
    "        colList = [ x for x in col.find().limit(limit)]\n",
    "    return(colList)\n",
    "\n",
    "def colRawFind(limit=\"\"):\n",
    "    if limit == \"\":\n",
    "        colList = [ x for x in col.find_raw_batches()]\n",
    "    else:\n",
    "        colList = [ b.decode_all(x) for x in col.find_raw_batches().limit(limit)]\n",
    "    return(colList)\n",
    "\n",
    "def colFindID():\n",
    "    idList = [str(x).split(\"'\",4)[3] for x in col.find({},{\"_id\":1}).limit(5)]\n",
    "    return(idList)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PYSPARK METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SCHEMA = spark.read\\\n",
    "                .format( \"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "                .option('spark.mongodb.input.uri', uri_string)\\\n",
    "                .option('spark.mongodb.input.sampleSize', 100)\\\n",
    "                .option(\"spark.mongodb.input.database\", \"local\")\\\n",
    "                .option(\"spark.mongodb.input.collection\", \"local_test\")\\\n",
    "                .load().schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_id',\n",
       " 'cnpj',\n",
       " 'codigo_qualificacao_socio',\n",
       " 'codigo_tipo_socio',\n",
       " 'cpf_cnpj_socio',\n",
       " 'nome_socio',\n",
       " 'qualificacao_socio',\n",
       " 'razao_social',\n",
       " 'tipo_socio']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_COLS = spark.read\\\n",
    "            .schema(DATA_SCHEMA)\\\n",
    "            .format( \"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "            .option('spark.mongodb.input.uri', uri_string)\\\n",
    "            .option(\"spark.mongodb.input.database\", \"local\")\\\n",
    "            .option(\"spark.mongodb.input.collection\", \"local_test\")\\\n",
    "            .load().columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md USO DE SQUEMA OTIMIZADO REDUZIU A QUERY EM 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27420729"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "   \n",
    "DATA_IDS = DATA_COLS = spark.read\\\n",
    "            .schema(DATA_SCHEMA)\\\n",
    "            .format( \"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "            .option('spark.mongodb.input.uri', uri_string)\\\n",
    "            .option(\"spark.mongodb.input.database\", \"local\")\\\n",
    "            .option(\"spark.mongodb.input.collection\", \"local_test\")\\\n",
    "            .load().select(\"_id\")\n",
    "DATA_IDS.count()      \n",
    "\n",
    "\n",
    "#----5m2.4s  \n",
    "DATA_IDS_SCHEMA = DATA_COLS = spark.read\\\n",
    "            .schema(DATA_SCHEMA)\\\n",
    "            .format( \"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "            .option('spark.mongodb.input.uri', uri_string)\\\n",
    "            .option('spark.mongodb.input.sampleSize', 50)\\\n",
    "            .option(\"spark.mongodb.input.database\", \"local\")\\\n",
    "            .option(\"spark.mongodb.input.collection\", \"local_test\")\\\n",
    "            .load().select(\"_id\").schema\n",
    "\n",
    "\n",
    "\n",
    "#----4m1.1s \n",
    "DATA_IDS_S_FILTER = DATA_COLS = spark.read\\\n",
    "            .schema(DATA_IDS_SCHEMA)\\\n",
    "            .format( \"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "            .option('spark.mongodb.input.uri', uri_string)\\\n",
    "            .option(\"spark.mongodb.input.database\", \"local\")\\\n",
    "            .option(\"spark.mongodb.input.collection\", \"local_test\")\\\n",
    "            .load()\n",
    "\n",
    "DATA_IDS_S_FILTER.count()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md #metodos altenarivos de seleção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+-------------------------+-----------------+--------------+--------------------+------------------+------------------+-------------+\n",
      "|                 _id|          cnpj|codigo_qualificacao_socio|codigo_tipo_socio|cpf_cnpj_socio|          nome_socio|qualificacao_socio|      razao_social|   tipo_socio|\n",
      "+--------------------+--------------+-------------------------+-----------------+--------------+--------------------+------------------+------------------+-------------+\n",
      "|{615fbce78969fa8e...|00000000296376|                       10|                2|   ***760516**|DELANO VALENTIM D...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       16|                2|   ***470447**|RUBEM DE FREITAS ...|        Presidente|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***431620**|GERSON EDUARDO DE...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***760516**|DELANO VALENTIM D...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***875581**|ANA PAULA TEIXEIR...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***213833**|JOSE AVELAR MATIA...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***662506**|LUIZ CLAUDIO BATISTA|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***370266**|ANTONIO GUSTAVO M...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***890627**|BERNARDO DE AZEVE...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***295868**|          CARLA NESI|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***653918**|MARCOS RENATO COLTRI|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***261501**|JOSE RICARDO FAGO...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***309199**|     LUCINEIA POSSAR|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***794793**|CARLOS HAMILTON V...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***347521**|JOAO PINTO RABELO...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***677786**|MARCO TULIO MORAE...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***916073**|JOSE EDUARDO PERE...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***198248**|CARLOS RENATO BON...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***907166**|JOSE CAETANO DE A...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "|{615fbce78969fa8e...|00000000000353|                       10|                2|   ***390059**|REINALDO KAZUFUMI...|           Diretor|BANCO DO BRASIL SA|Pessoa Física|\n",
      "+--------------------+--------------+-------------------------+-----------------+--------------+--------------------+------------------+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "DATA_ =  spark.read\\\n",
    "            .schema(DATA_SCHEMA)\\\n",
    "            .format( \"com.mongodb.spark.sql.DefaultSource\")\\\n",
    "            .option('spark.mongodb.input.sampleSize', 10)\\\n",
    "            .option('spark.mongodb.input.uri', uri_string)\\\n",
    "            .option(\"spark.mongodb.input.database\", \"local\")\\\n",
    "            .option(\"spark.mongodb.input.collection\", \"local_test\")\\\n",
    "            .load().select(['_id',\n",
    "                            'cnpj',\n",
    "                            'codigo_qualificacao_socio',\n",
    "                            'codigo_tipo_socio',\n",
    "                            'cpf_cnpj_socio',\n",
    "                            'nome_socio',\n",
    "                            'qualificacao_socio',\n",
    "                            'razao_social',\n",
    "                            'tipo_socio']).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PARALLEL METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxRunWorkerTask(ID=None):\n",
    "    #TRANSFORMATION FUNC\n",
    "\n",
    "    QUERY = db.client.get_database(\"local\").get_collection(\"SPT\").find({ 'match' : {'_id': ID}})     \n",
    "    for x in QUERY:\n",
    "        RESULT_LIST.append(x)\n",
    "    \n",
    "\n",
    "def maxRunWorker(max_workers=4, mode=\"submit\"):    \n",
    "    ID_LIST = colFindID()\n",
    "    T0 = datetime.now()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        if mode == \"submit\":\n",
    "            for x in ID_LIST:\n",
    "                executor.submit(maxRunWorkerTask, ID=x)\n",
    "        else:\n",
    "            executor.map(maxRunWorkerTask, ID_LIST)\n",
    "        \n",
    "    T1 = datetime.now()\n",
    "    print(f\" QUERY_TIME = {(T1-T0).seconds} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de2447fb81e3bdedb6496b06bacdb2c52fb1921ab17eb741c5f37bae09bc662a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
